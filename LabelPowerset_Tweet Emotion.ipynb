{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "deec8970-a5ad-419b-ad12-94d222776607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.metrics import accuracy_score,hamming_loss,classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2fd6e16e-7eb5-4635-9004-38ab9c05f724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Labels_t1</th>\n",
       "      <th>Labels_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NO JOKE I WILL HOP ON A PLANE RN! (Well after ...</td>\n",
       "      <td>0 10</td>\n",
       "      <td>optimistic','joking'</td>\n",
       "      <td>['optimistic','joking']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>BanMediaHouse whose is responsible for spreadi...</td>\n",
       "      <td>6</td>\n",
       "      <td>annoyed'</td>\n",
       "      <td>['annoyed']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Im waiting for someone to say to me that all t...</td>\n",
       "      <td>3 4</td>\n",
       "      <td>pessimistic','anxious'</td>\n",
       "      <td>['pessimistic','anxious']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>He is a liar. Proven day night. Time again. Li...</td>\n",
       "      <td>6</td>\n",
       "      <td>annoyed'</td>\n",
       "      <td>['annoyed']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NEW: U.S. CoronaVirus death toll reaches 4,000...</td>\n",
       "      <td>8</td>\n",
       "      <td>surprise'</td>\n",
       "      <td>['surprise']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                              Tweet Labels  \\\n",
       "0   1  NO JOKE I WILL HOP ON A PLANE RN! (Well after ...   0 10   \n",
       "1   2  BanMediaHouse whose is responsible for spreadi...      6   \n",
       "2   3  Im waiting for someone to say to me that all t...    3 4   \n",
       "3   4  He is a liar. Proven day night. Time again. Li...      6   \n",
       "4   5  NEW: U.S. CoronaVirus death toll reaches 4,000...      8   \n",
       "\n",
       "                Labels_t1                   Labels_t  \n",
       "0    optimistic','joking'    ['optimistic','joking']  \n",
       "1                annoyed'                ['annoyed']  \n",
       "2  pessimistic','anxious'  ['pessimistic','anxious']  \n",
       "3                annoyed'                ['annoyed']  \n",
       "4               surprise'               ['surprise']  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the training dataset\n",
    "train_data = pd.read_csv('/Users/meimei/Documents/UT1/Data Analytics/sentiment-analysis-of-covid-19-related-tweets/training_T2.csv', header=0, delimiter=',')\n",
    "\n",
    "#Show the top part of the data table\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f09138c4-8600-4dd2-bdcc-e47280f01f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45bbca5f-7006-4590-a143-6559d5a37bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NO JOKE I WILL HOP ON A PLANE RN! (Well after ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>BanMediaHouse whose is responsible for spreadi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Im waiting for someone to say to me that all t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>He is a liar. Proven day night. Time again. Li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NEW: U.S. CoronaVirus death toll reaches 4,000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                              Tweet\n",
       "0   1  NO JOKE I WILL HOP ON A PLANE RN! (Well after ...\n",
       "1   2  BanMediaHouse whose is responsible for spreadi...\n",
       "2   3  Im waiting for someone to say to me that all t...\n",
       "3   4  He is a liar. Proven day night. Time again. Li...\n",
       "4   5  NEW: U.S. CoronaVirus death toll reaches 4,000..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the X variables\n",
    "X_train = train_data.drop([\"Labels\",\"Labels_t1\",\"Labels_t\"], axis=1)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd46e3d8-43b1-4c98-a181-a999927e75a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"['optimistic','joking']\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(train_data['Labels_t'].iloc[0]))\n",
    "train_data['Labels_t'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c6da4d0-1f3d-4141-b8c1-c162b7c043ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "ast.literal_eval(train_data['Labels_t'].iloc[0])\n",
    "train_data['Labels_t'] = train_data['Labels_t'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbfa8f38-9a5d-41c4-9780-c2f588fdfa3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    [optimistic, joking]\n",
       "1                                               [annoyed]\n",
       "2                                  [pessimistic, anxious]\n",
       "3                                               [annoyed]\n",
       "4                                              [surprise]\n",
       "                              ...                        \n",
       "4995                               [anxious, sad, denial]\n",
       "4996                                       [anxious, sad]\n",
       "4997    [pessimistic, sad, official_report, thankfulop...\n",
       "4998                [official_report, thankfuloptimistic]\n",
       "4999                        [annoyed, thankfuloptimistic]\n",
       "Name: Labels_t, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Labels_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "57c0a259-deb9-4780-b079-d31d0a75b74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [optimistic, joking]\n",
       "1                 [annoyed]\n",
       "2    [pessimistic, anxious]\n",
       "3                 [annoyed]\n",
       "4                [surprise]\n",
       "Name: Labels_t, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the u variables\n",
    "y = train_data[\"Labels_t\"]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0df820af-26b6-4f12-a7ca-04c855d763f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list(['optimistic', 'joking']) list(['annoyed'])\n",
      " list(['pessimistic', 'anxious']) ...\n",
      " list(['pessimistic', 'sad', 'official_report', 'thankfuloptimistic'])\n",
      " list(['official_report', 'thankfuloptimistic'])\n",
      " list(['annoyed', 'thankfuloptimistic'])]\n",
      "NumOfLabels: 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>joking</td>\n",
       "      <td>1777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>annoyed</td>\n",
       "      <td>1725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>optimistic</td>\n",
       "      <td>1180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sad</td>\n",
       "      <td>1088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>official_report</td>\n",
       "      <td>914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anxious</td>\n",
       "      <td>842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pessimistic</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>surprise</td>\n",
       "      <td>604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>thankfuloptimistic</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>denial</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                label  count\n",
       "1              joking   1777\n",
       "2             annoyed   1725\n",
       "0          optimistic   1180\n",
       "6                 sad   1088\n",
       "8     official_report    914\n",
       "4             anxious    842\n",
       "3         pessimistic    620\n",
       "5            surprise    604\n",
       "9  thankfuloptimistic    480\n",
       "7              denial    314"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = train_data['Labels_t'].values\n",
    "print(labels)\n",
    "\n",
    "label_dic={}\n",
    "for label_list in labels:\n",
    "    for label in label_list:        \n",
    "        if label not in label_dic:\n",
    "            label_dic[label]=1\n",
    "        else:\n",
    "             label_dic[label]+=1\n",
    "df = pd.DataFrame(list(label_dic.items()), columns=['label', 'count']).sort_values(by = 'count',axis = 0,ascending = False)\n",
    "print('NumOfLabels:',len(df))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1af75d8-1751-44c1-b9d9-7fcf821ef377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming negation abbreviated text to standard text\n",
    "re_negation = re.compile(\"n't \") #regular expression rule\n",
    "\n",
    "def negation_abbreviation_to_regular(abbreviated_text):\n",
    "    '''\n",
    "    aren't -> are not \n",
    "    '''\n",
    "    regular_text = re_negation.sub(' not ', abbreviated_text)    \n",
    "    return regular_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36d6e01c-f50b-4240-a09a-29b37f54fcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the stopwords list from the nltk library\n",
    "stopwords_list = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9a9726d-a81e-4a7e-9ae8-dfd536c0f838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatized the words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_lemmatized_words(words_list):\n",
    "    '''\n",
    "        cats -> cat\n",
    "        houses to house\n",
    "        apples to apple\n",
    "        started to start (v)\n",
    "    '''    \n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words_list]\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, \"v\") for word in lemmatized_words]\n",
    "    \n",
    "    return lemmatized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "358b543d-300c-47bf-aa07-375bd49cf2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_review(raw_review):\n",
    "    '''\n",
    "        cleaning the review text\n",
    "    '''\n",
    "    #remove html tags from the raw review\n",
    "    review_text = BeautifulSoup(raw_review).get_text()\n",
    "    \n",
    "    #transforming the negation abbreviated terms to regular terms\n",
    "    review_text_regular = negation_abbreviation_to_regular(review_text)\n",
    "    \n",
    "    #removing non-alphanumeric terms\n",
    "    review_text_alphanum = re.sub(\"[^a-zA-Z_0-9]\", \" \", review_text_regular)\n",
    "    \n",
    "    #converting the characters into lowercase\n",
    "    review_text_lower_case = review_text_alphanum.lower()\n",
    "\n",
    "    #tokenize the text into words\n",
    "    review_words = review_text_lower_case.split()\n",
    "    \n",
    "    #removing stop words\n",
    "    review_words_meaningful = [word for word in review_words if word not in stopwords_list]\n",
    "    \n",
    "    #lematization\n",
    "    review_words_lemmatized = get_lemmatized_words(review_words_meaningful)\n",
    "    \n",
    "    clean_review = \" \".join(review_words_lemmatized)\n",
    "    return clean_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "44c01d05-875c-456e-aeb8-a791e8e63ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning reviews\n",
    "train_reviews_clean = []\n",
    "for review in X_train['Tweet']:\n",
    "    clean_review = get_clean_review(review)\n",
    "    train_reviews_clean.append(clean_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae4b1c11-9a62-443b-b455-bb592c091861",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "138cfc4f-77c9-4dd5-854b-d7df5e2d873b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorization the text data\n",
    "#vectorizer = TfidfVectorizer(max_features=10000, ngram_range = (1,2))\n",
    "vectorizer = CountVectorizer(max_features=10000, ngram_range = (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d73604a5-73ab-46a1-b9e6-d7be9ddd9807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 10000)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xfeatures = vectorizer.fit_transform(train_reviews_clean)\n",
    "Xfeatures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de45aa93-557c-4dd5-9fed-9888db8c320c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xfeatures.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "59e073b9-3c1b-4239-9d77-2243eac0a45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slip the data\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(Xfeatures,y,test_size=0.2,random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "29435525-0acf-4915-9c0b-9f22ed80c268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ae4c4eef-3555-4f8e-931c-30177d2586ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: LabelPowerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "03f71092-4da3-4f5b-983b-a73219b7a1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['annoyed', 'anxious', 'denial', 'empathetic', 'joking',\n",
       "       'official_report', 'optimistic', 'pessimistic', 'sad', 'surprise',\n",
       "       'thankful', 'thankfuloptimistic'], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build model\n",
    "#covert the multi-label\n",
    "mlt=MultiLabelBinarizer()\n",
    "Y_train_convert= mlt.fit_transform(Y_train)\n",
    "Y_test_convert = mlt.fit_transform(Y_test)\n",
    "mlt.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "868843c1-e2c5-43f4-ba5d-2d9819815048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fff6ae13-0528-4b9a-9d10-be28d6eb41a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train1 = mlt.inverse_transform(Y_train_convert)\n",
    "#print(Y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c9ab2295-990c-41ff-8550-45fe7624e7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model,mlb_estimator,xtrain,ytrain,xtest,ytest):\n",
    "    # Create an Instance\n",
    "    clf = mlb_estimator(model)\n",
    "    clf.fit(xtrain,ytrain)\n",
    "    # Predict\n",
    "    clf_predictions = clf.predict(xtest)\n",
    "    # Check For Accuracy\n",
    "    acc = accuracy_score(ytest,clf_predictions)\n",
    "    ham = hamming_loss(ytest,clf_predictions)\n",
    "    result = {\"accuracy:\":acc,\"hamming_score\":ham}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4168df49-ee1b-4194-9eeb-beeafc3e7926",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_labelP_model = build_model(MultinomialNB(),LabelPowerset,X_train,Y_train_convert,X_test,Y_test_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7fcb039f-daf6-44ff-a0cd-567275c7f54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy:': 0.162, 'hamming_score': 0.19691666666666666}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_labelP_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a792ac27-62dd-44cc-8756-eba96f504430",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LabelPowerset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jt/z3qyvs0128g_pdpmxjd_t_pw0000gn/T/ipykernel_63410/3244551174.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelPowerset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train_convert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LabelPowerset' is not defined"
     ]
    }
   ],
   "source": [
    "modelLP = LabelPowerset(MultinomialNB())\n",
    "modelLP.fit(X_train,Y_train_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c612f454-6b74-4455-9574-f6f1490df743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5001</td>\n",
       "      <td>Forgot to a math test and I was failing but my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5002</td>\n",
       "      <td>Corona effected came from Delhi in Bihar lakhi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5003</td>\n",
       "      <td>Make CORONA END NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5004</td>\n",
       "      <td>Imagine if the coronavirus pandemic was a big ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5005</td>\n",
       "      <td>Howdy Ana. Where can I get married during the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID                                              Tweet\n",
       "0  5001  Forgot to a math test and I was failing but my...\n",
       "1  5002  Corona effected came from Delhi in Bihar lakhi...\n",
       "2  5003                                 Make CORONA END NA\n",
       "3  5004  Imagine if the coronavirus pandemic was a big ...\n",
       "4  5005  Howdy Ana. Where can I get married during the ..."
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#processing the test dataset\n",
    "\n",
    "#loading the testing dataset\n",
    "test_data = pd.read_csv('/Users/meimei/Documents/UT1/Data Analytics/sentiment-analysis-of-covid-19-related-tweets/validation.csv', header=0, delimiter=',')\n",
    "\n",
    "#Show the top part of the data table\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7df41e71-e3e0-434e-91e2-b454b683a75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2500 entries, 0 to 2499\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ID      2500 non-null   int64 \n",
      " 1   Tweet   2500 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 39.2+ KB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a328836d-c137-41d1-9315-966fc644d1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Forgot to a math test and I was failing but my teacher opening it back up, maybe corona aint so bad'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pre = test_data['Tweet']\n",
    "X_pre[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "97e3fd1a-c3cb-4b32-98d0-532551f7d417",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning test reviews\n",
    "test_reviews_clean = []\n",
    "for review in X_pre:\n",
    "    clean_review = get_clean_review(review)\n",
    "    test_reviews_clean.append(clean_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eac38402-9c4a-4280-9a51-d3fd45f23a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize the test reviews\n",
    "X_pre_features = vectorizer.fit_transform(test_reviews_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "58d5e265-72d3-4052-9fdf-78b33b4f49d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "#use first model to predict\n",
    "clf_predictions = modelLP.predict(X_pre_features)\n",
    "Y_pred = mlt.inverse_transform(clf_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8b18fb43-ffc0-4c4e-b42f-72ad624a85ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jt/z3qyvs0128g_pdpmxjd_t_pw0000gn/T/ipykernel_62736/1430702186.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_pred_convert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/DT/lib/python3.9/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, yt)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m             raise ValueError(\n\u001b[1;32m    902\u001b[0m                 \"Expected indicator for {0} classes, but got {1}\".format(\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "test_pred_convert = mlt.inverse_transform(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3879d7ec-34c4-4e5b-a638-5e0babf8f926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID                 Labels\n",
      "0  5001      (annoyed, joking)\n",
      "1  5002  (thankfuloptimistic,)\n",
      "2  5003   (joking, optimistic)\n",
      "3  5004  (joking, pessimistic)\n",
      "4  5005  (thankfuloptimistic,)\n"
     ]
    }
   ],
   "source": [
    "test_output = pd.DataFrame(data={\"ID\":test_data['ID'], \"Labels\":Y_pred})\n",
    "print(test_output.head())\n",
    "\n",
    "test_output.to_csv('/Users/meimei/Documents/UT1/Data Analytics/sentiment-analysis-of-covid-19-related-tweets/prediction2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
